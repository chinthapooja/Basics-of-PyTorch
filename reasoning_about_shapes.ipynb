{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Reasoning about shapes in PyTorch is crucial for understanding how tensors flow through your neural network model and ensuring that operations are compatible. Here are some key aspects to consider when reasoning about shapes in PyTorch:\n",
        "\n",
        "**Input Shape:** Understand the shape of your input data. For example, if you're working with image data, the shape might be (batch_size, channels, height, width).\n",
        "\n",
        "**Layer Operations:** Each layer in your neural network will typically change the shape of the data it operates on. For instance, a convolutional layer might reduce the spatial dimensions while increasing the depth (number of channels).\n",
        "\n",
        "**Parameters:**Some layers, like fully connected (linear) layers, have parameters that affect the output shape. For example, a linear layer will reshape the input tensor based on the number of input and output units specified.\n",
        "\n",
        "**Batch Dimension:** The batch dimension (batch_size) affects the shape of tensors as they flow through the network. It's important to keep track of this dimension, especially when implementing batch normalization or handling mini-batch training.\n",
        "\n",
        "**Padding and Stride:** Convolutional layers with padding and stride parameters can affect the output shape. Padding adds extra rows and columns around the input, while stride determines the step size of the kernel as it moves across the input.\n",
        "\n",
        "**Pooling Operations:** Pooling layers (e.g., max pooling, average pooling) reduce the spatial dimensions of the input tensor while preserving the number of channels.\n",
        "\n",
        "**Concatenation and Stacking:** Concatenating or stacking tensors together can change their shapes, especially along the concatenation dimension.\n",
        "\n",
        "**Transposition and Reshaping:** Operations like transposition (torch.transpose) or reshaping (torch.reshape) can be used to manipulate tensor shapes explicitly.\n",
        "\n",
        "**Output Shape:** Finally, it's essential to understand the shape of the output tensor produced by your model, especially when defining loss functions and evaluating performance.\n",
        "\n",
        "By carefully reasoning about tensor shapes at each step of your model's forward pass, you can ensure that operations are compatible and debug any shape-related issues effectively. Visualizing the shapes of tensors at different stages of your network can also be helpful for understanding how data flows through the model."
      ],
      "metadata": {
        "id": "bPlchHjtEMP_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izb9Ux8fCnI0",
        "outputId": "9ece0cf6-6330-4c94-da90-d7e8d4e2e7cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(..., device='meta', size=(2, 5, 9, 9), grad_fn=<ConvolutionBackward0>)\n",
            "Time taken: 0.024652957000000697\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import timeit\n",
        "\n",
        "t = torch.rand(2, 3, 10, 10, device=\"meta\")\n",
        "conv = torch.nn.Conv2d(3, 5, 2, device=\"meta\")\n",
        "start = timeit.default_timer()\n",
        "out = conv(t)\n",
        "end = timeit.default_timer()\n",
        "\n",
        "print(out)\n",
        "print(f\"Time taken: {end-start}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_large = torch.rand(2**10, 3, 2**16, 2**16, device=\"meta\")\n",
        "start = timeit.default_timer()\n",
        "out = conv(t_large)\n",
        "end = timeit.default_timer()\n",
        "\n",
        "print(out)\n",
        "print(f\"Time taken: {end-start}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XxvYHs2-CrVq",
        "outputId": "fd0aef8a-92ce-4d25-b02e-2acfd14779eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(..., device='meta', size=(1024, 5, 65535, 65535),\n",
            "       grad_fn=<ConvolutionBackward0>)\n",
            "Time taken: 0.006431813999995484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "R-mCmp6rCsqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fw_hook(module, input, output):\n",
        "    print(f\"Shape of output to {module} is {output.shape}.\")\n",
        "\n",
        "\n",
        "# Any tensor created within this torch.device context manager will be\n",
        "# on the meta device.\n",
        "with torch.device(\"meta\"):\n",
        "    net = Net()\n",
        "    inp = torch.randn((1024, 3, 32, 32))\n",
        "\n",
        "for name, layer in net.named_modules():\n",
        "    layer.register_forward_hook(fw_hook)\n",
        "\n",
        "out = net(inp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q30wmckdCuKX",
        "outputId": "049b569f-13ec-4cb7-df8b-b595398a6c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of output to Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1)) is torch.Size([1024, 6, 28, 28]).\n",
            "Shape of output to MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) is torch.Size([1024, 6, 14, 14]).\n",
            "Shape of output to Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1)) is torch.Size([1024, 16, 10, 10]).\n",
            "Shape of output to MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False) is torch.Size([1024, 16, 5, 5]).\n",
            "Shape of output to Linear(in_features=400, out_features=120, bias=True) is torch.Size([1024, 120]).\n",
            "Shape of output to Linear(in_features=120, out_features=84, bias=True) is torch.Size([1024, 84]).\n",
            "Shape of output to Linear(in_features=84, out_features=10, bias=True) is torch.Size([1024, 10]).\n",
            "Shape of output to Net(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ") is torch.Size([1024, 10]).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statement: \"One way around this is to run the forward pass with random inputs, but this is wasteful in terms of memory and compute.\"\n",
        "\n",
        "Explanation: One approach to determining the output shapes of a layer in a neural network is to run a forward pass with random inputs through the layer. By doing so, we can observe the shapes of the output tensors produced by the layer. However, this method can be inefficient because it requires allocating memory for the input data and performing computations, even though we are not interested in the actual output values.\n",
        "\n",
        "Example:\n",
        "Suppose we have a convolutional neural network (CNN) with a convolutional layer. We want to determine the shape of the output feature maps produced by this convolutional layer for a given input size and set of convolutional parameters (e.g., kernel size, stride, padding). One way to do this is by running a forward pass with random input data through the convolutional layer and inspecting the shapes of the output tensors."
      ],
      "metadata": {
        "id": "ZuYrfFSDLER4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a convolutional layer\n",
        "conv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "# Generate random input data with a specific shape\n",
        "batch_size = 1\n",
        "channels = 3\n",
        "height = 32\n",
        "width = 32\n",
        "random_input = torch.randn(batch_size, channels, height, width)\n",
        "\n",
        "# Perform a forward pass through the convolutional layer\n",
        "output = conv_layer(random_input)\n",
        "\n",
        "# Print the shape of the output tensor\n",
        "print(\"Output shape:\", output.shape)\n"
      ],
      "metadata": {
        "id": "mRsnlPTYCvq4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2df80a0f-3b3b-4467-c124-fdbec1cfaa52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([1, 16, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example:\n",
        "\n",
        "We create a convolutional layer (conv_layer) with input channels (in_channels) set to 3 (assuming RGB images) and output channels (out_channels) set to 16.\n",
        "We generate random input data (random_input) with a batch size of 1, 3 input channels, and spatial dimensions of 32x32.\n",
        "We perform a forward pass through the convolutional layer with the random input data to obtain the output tensor (output).\n",
        "Finally, we print the shape of the output tensor, which gives us insight into the shape of the feature maps produced by the convolutional layer.\n",
        "While this approach provides us with the desired output shapes, it involves unnecessary computation and memory usage, especially if we are only interested in the shapes and not the actual output values."
      ],
      "metadata": {
        "id": "v8nNQUp2LMr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statement: \"Instead, we can make use of the meta device to determine the output shapes of a layer without materializing any data.\"\n",
        "\n",
        "Explanation: Instead of running a forward pass with random inputs, we can leverage PyTorch's meta device to determine the output shapes of a layer without actually materializing any data. The meta device allows us to perform operations at a meta level, enabling us to query properties of tensors, such as their shapes, without performing actual computations."
      ],
      "metadata": {
        "id": "RoM_LeepLNhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define a convolutional layer\n",
        "conv_layer = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "# Create a dummy input tensor with the desired shape\n",
        "dummy_input_shape = (1, 3, 32, 32)\n",
        "\n",
        "# Use the meta device to determine the output shape without materializing any data\n",
        "with torch.no_grad():\n",
        "    dummy_input = torch.randn(dummy_input_shape, device=torch.device('meta'))\n",
        "    output_shape = conv_layer(dummy_input).shape\n",
        "\n",
        "# Print the output shape\n",
        "print(\"Output shape:\", output_shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BMZFvNtLIAg",
        "outputId": "8d4773a1-1f07-49a9-b642-562536dadfcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output shape: torch.Size([1, 16, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example:\n",
        "\n",
        "We define a convolutional layer (conv_layer) with the same parameters as before.\n",
        "Instead of generating random input data, we create a dummy input tensor shape (dummy_input_shape) with the desired shape (1 sample, 3 channels, 32x32 spatial dimensions).\n",
        "We use torch.no_grad() to prevent gradients from being computed during the forward pass, as we are only interested in determining the output shape.\n",
        "We create a dummy input tensor (dummy_input) with the desired shape and specify the meta device.\n",
        "We pass the dummy input tensor through the convolutional layer to obtain the output shape (output_shape) without materializing any actual data.\n",
        "Finally, we print the output shape, which gives us the desired information without the need for memory-intensive computations.\n",
        "Using the meta device in this way allows us to efficiently determine the output shapes of layers without incurring the overhead of running a full forward pass with random inputs. This can be particularly useful when designing and debugging neural network architectures."
      ],
      "metadata": {
        "id": "tzckm7k6LTWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**what will happen if we specify the meta device.**"
      ],
      "metadata": {
        "id": "mzpVnXbXLWyD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you specify the meta device in PyTorch, it means that the operations performed on tensors with this device are executed at a \"meta\" level. In other words, these operations are not executed on actual computational devices like CPU or GPU, but rather they are used for meta-computations such as shape inference or other high-level operations.\n",
        "\n",
        "When you specify the meta device, PyTorch will not allocate memory or compute gradients for tensors on this device. Instead, it will perform operations that don't require actual numerical values, such as shape inference, dtype inference, or querying tensor properties.\n",
        "\n",
        "Here's what happens if you specify the meta device:\n",
        "\n",
        "No Memory Allocation: Tensors with the meta device won't occupy memory on any physical device. This can be useful when you want to perform operations that only require shape inference or dtype inference without actually storing any data.\n",
        "\n",
        "No Compute: Operations performed on tensors with the meta device won't involve actual numerical computation. This means that gradients won't be computed, and no computations will be executed on CPU or GPU devices.\n",
        "\n",
        "Shape Inference: You can use the meta device to infer the shape of tensors without materializing any data. This can be helpful for designing neural network architectures or debugging code where you need to know the shape of tensors without performing actual computations.\n",
        "\n",
        "Efficient Meta-Computation: By using the meta device, you can efficiently perform high-level meta-computations that don't require actual numerical values. This can save computational resources and improve performance, especially when dealing with complex architectures or large-scale models.\n",
        "\n",
        "Overall, specifying the meta device allows you to perform meta-computations efficiently in PyTorch without incurring the overhead of memory allocation or numerical computation on physical devices. It's particularly useful for tasks like shape inference, dtype inference, or tensor property querying.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NcdMasEaLY8V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "can you elabarote more \"If you specify the meta device in PyTorch, it means that the operations performed on tensors with this device are executed at a \"meta\" level. \"? what is meant by meta level"
      ],
      "metadata": {
        "id": "nc5EXkpvLewv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Certainly! When we refer to \"meta level\" in the context of PyTorch's meta device, we're describing a level of abstraction above the traditional computational devices like CPU or GPU. Let's delve into this concept further:\n",
        "\n",
        "Meta-Level Operations: Operations executed at the meta level involve tasks that don't directly involve numerical computation but rather pertain to the structure, properties, or metadata of tensors. These operations include tasks such as shape inference, dtype inference, or querying tensor properties like shape or dtype.\n",
        "\n",
        "Abstraction: The term \"meta\" implies a higher level of abstraction. In this context, it means that operations performed on tensors with the meta device are abstracted away from the details of numerical computation and focus more on the structural or property-related aspects of tensors.\n",
        "\n",
        "Shape Inference: One common use of the meta device is for shape inference, where you can determine the shape of tensors without materializing any data or performing actual computations. This abstraction allows you to reason about tensor shapes without the need for memory allocation or compute resources.\n",
        "\n",
        "Efficiency: Performing operations at the meta level can be more efficient in terms of computational resources compared to traditional numerical computations. Since these operations don't involve actual numerical values, they can be executed more quickly and with less overhead.\n",
        "\n",
        "Debugging and Design: Working at the meta level can be particularly useful for tasks like debugging neural network architectures or designing complex models. You can quickly infer tensor shapes, inspect tensor properties, or perform other high-level operations without the need for extensive computational resources.\n",
        "\n",
        "In summary, operating at the \"meta level\" with the meta device in PyTorch involves performing high-level operations that focus on the structure, properties, or metadata of tensors rather than numerical computation. This abstraction provides efficiency and flexibility for tasks such as shape inference, debugging, or design in deep learning workflows."
      ],
      "metadata": {
        "id": "eNE32wIZLgOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "what is meant by metadata of tensors? metadata of tensors rather than numerical computation. ?"
      ],
      "metadata": {
        "id": "3_wK656WLmH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metadata of tensors refers to additional information or attributes associated with tensors that describe their properties, but do not directly involve numerical computation. This metadata provides valuable context about the tensors, which can be useful for various tasks such as debugging, analysis, or optimization. Here are some common examples of metadata associated with tensors:\n",
        "\n",
        "Shape: The shape of a tensor specifies the number of dimensions and the size of each dimension. For example, a tensor with shape (3, 4) has 3 rows and 4 columns. Understanding the shape of tensors is essential for ensuring compatibility in operations and for designing neural network architectures.\n",
        "\n",
        "Data Type (dtype): The data type of a tensor indicates the type of elements it contains, such as integers, floating-point numbers, or boolean values. Common data types in PyTorch include torch.float32, torch.int64, and torch.bool. Knowing the dtype is crucial for numerical operations and memory management.\n",
        "\n",
        "Device: The device on which a tensor is located, such as CPU or GPU. PyTorch supports devices like torch.device('cpu') and torch.device('cuda'). Understanding the device placement of tensors is important for efficient computation, especially in distributed or GPU-accelerated settings.\n",
        "\n",
        "Requires Grad: This attribute indicates whether a tensor requires gradient computation for automatic differentiation during backpropagation. If requires_grad is set to True, PyTorch tracks operations on the tensor for gradient computation. This is essential for training neural networks with gradient-based optimization algorithms.\n",
        "\n",
        "Stride: Stride refers to the number of elements to jump in each dimension when traversing a tensor. Stride information is useful for efficient memory access and slicing operations.\n",
        "\n",
        "Layout: The memory layout of a tensor, which can be either contiguous or non-contiguous. Contiguous tensors have elements stored in a single, contiguous block of memory, while non-contiguous tensors may have elements scattered across memory. Contiguous tensors typically have better performance due to memory locality.\n",
        "\n",
        "Version Counter: PyTorch tensors have a version counter that is updated whenever the tensor's data is modified in-place. This is used for detecting changes and ensuring correctness in operations that rely on tensor state.\n",
        "\n",
        "Gradient: If a tensor is part of a computational graph and requires gradient computation (requires_grad=True), its grad attribute stores the gradient computed during backpropagation. This is used for updating model parameters during optimization.\n",
        "\n",
        "These metadata attributes provide valuable context about tensors, enabling users to understand their properties, track their state, and perform various operations efficiently. While numerical computation involves manipulating tensor elements, metadata provides complementary information that is essential for effective tensor management and manipulation."
      ],
      "metadata": {
        "id": "_KDVLFmjLp4v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQthyFI-LQsY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}